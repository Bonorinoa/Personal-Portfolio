{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd2anTcQPTYp"
      },
      "source": [
        "## MATH 462 - Homework 4\n",
        "\n",
        "Augusto Gonzalez-Bonorino\n",
        "\n",
        "### Part I\n",
        "\n",
        "Chapter 6, exercises 7 and 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJnLxv-XWy-m"
      },
      "source": [
        "#### Exercise 6\n",
        "\n",
        "To streamline the experiments varying data set size, i wrote a utility function that parameterizes this argument.\n",
        "\n",
        "*run_experiment* takes in an integer, denoting the size of the dataset to generate, and then uses scikit-learn's *make_moons* method to create a clustered dataset from classification. After proper data splitting, grid search cross validation is used to find the best hyperparameters for a decision tree classifier. The function returns the best tree model estimated, it's accuracy score, and the data splits for convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRnqQIkIO1Lb",
        "outputId": "5a0209b5-2e44-400f-dacc-28c15938a6ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best performing decision tree (1000): \n",
            "\n",
            "- DecisionTreeClassifier(max_depth=2, max_leaf_nodes=4, random_state=42)\n",
            "Performance metrics: \n",
            "\n",
            "- Accuracy: 0.79\n",
            "\n",
            "Best performing decision tree (10000): \n",
            "\n",
            "- DecisionTreeClassifier(max_depth=2, max_leaf_nodes=4, random_state=42)\n",
            "Performance metrics: \n",
            "\n",
            "- Accuracy: 0.823\n",
            "\n",
            "Best performing decision tree (100000): \n",
            "\n",
            "- DecisionTreeClassifier(max_depth=2, max_leaf_nodes=4, random_state=42)\n",
            "Performance metrics: \n",
            "\n",
            "- Accuracy: 0.81745\n",
            "\n",
            "Best performing decision tree (1000000): \n",
            "\n",
            "- DecisionTreeClassifier(max_depth=2, max_leaf_nodes=4, random_state=42)\n",
            "Performance metrics: \n",
            "\n",
            "- Accuracy: 0.818965\n"
          ]
        }
      ],
      "source": [
        "# 6 task: change size of data set\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "## Experiment varying data set size\n",
        "def run_experiment(data_size):\n",
        "\n",
        "    X_moons, y_moons = make_moons(n_samples=data_size,\n",
        "                              noise=0.5,\n",
        "                              random_state=42)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_moons, y_moons,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "    params = {\n",
        "        'max_leaf_nodes': list(range(2, 10)),\n",
        "        'max_depth': list(range(1, 4)),\n",
        "        'min_samples_split': [2, 3]\n",
        "    }\n",
        "    grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
        "                                params,\n",
        "                                cv=3)\n",
        "\n",
        "    grid_search_cv.fit(X_train, y_train)\n",
        "\n",
        "    best_model = grid_search_cv.best_estimator_\n",
        "    accuracy = accuracy_score(grid_search_cv.predict(X_test), y_test)\n",
        "\n",
        "    split = (X_train, X_test, y_train, y_test)\n",
        "\n",
        "    return best_model, accuracy, split\n",
        "\n",
        "sizes = [1_000, 10_000, 100_000, 1_000_000]\n",
        "data_splits = []\n",
        "tree_models = []\n",
        "\n",
        "for size in sizes:\n",
        "    best_model, accuracy, split = run_experiment(size)\n",
        "    data_splits.append(split)\n",
        "    tree_models.append(best_model)\n",
        "\n",
        "    print(f\"\\nBest performing decision tree ({size}): \\n\\n- {best_model}\")\n",
        "    print(f\"Performance metrics: \\n\\n- Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sem_YgleWy-q"
      },
      "source": [
        "Interestingly, the accuracy of the decision tree classifier slightly drops with large datasets. The best model performed best for a dataset of size 10_000. I could consider retraining these models with a wider range of available values for the hyperparameters, and assess if efficacy changes with cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f16gNLTxWy-r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIZDQtJrWy-s"
      },
      "source": [
        "#### Exercise 8\n",
        "\n",
        "Following a similar coding practice as in the previous exercise, I create a series of utility functions to streamline the experiments. The function *build_mini_sets* takes in the number of instances to include in each split, the variable with the splits from the previous exercise, and the number of trees for populating the forest. It then creates the randomly shuffled \"mini\" training sets by choosing random indices to subset the original training matrix. Finally, a list with the mini training sets is returned.\n",
        "\n",
        "A second function, *build_forest*, is used te the forest via the method employed in the book. We create a list of clones of the best model we estimated in the previous exercise, train each cloned tree on the mini training sets and compute accuracy score for each. The function returns the forest model and the average accuracy score of all trees trained.\n",
        "\n",
        "Lastly, the *majority_vote_pred* function takes in the forest just created, the number of trees in the forest, and the original data splits. It creates a new list with the individual predictions or \"votes\" of each tree. A majority vote technique is implemented by computing the mode classication and comparing them to the true test values to estimate an overall accuracy score of the random forest via majority voting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PaMsOQbR-l3"
      },
      "outputs": [],
      "source": [
        "# 8 task: change size of n_instances randomly selected from training set\n",
        "\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.base import clone\n",
        "import numpy as np\n",
        "from scipy.stats import mode\n",
        "\n",
        "def build_mini_sets(size, data_split, num_trees):\n",
        "\n",
        "    n_instances = size\n",
        "\n",
        "    mini_sets = []\n",
        "\n",
        "    rs = ShuffleSplit(n_splits=num_trees, test_size=len(data_split[0]) - n_instances,\n",
        "                    random_state=42)\n",
        "\n",
        "    for mini_train_index, mini_test_index in rs.split(data_split[0]):\n",
        "        X_mini_train = data_split[0][mini_train_index]\n",
        "        y_mini_train = data_split[2][mini_train_index]\n",
        "        mini_sets.append((X_mini_train, y_mini_train))\n",
        "\n",
        "    return mini_sets\n",
        "\n",
        "def build_forest(tree_model, num_trees, mini_sets, data_split):\n",
        "\n",
        "    forest = [clone(tree_model) for _ in range(num_trees)]\n",
        "\n",
        "    accuracy_scores = []\n",
        "\n",
        "    for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):\n",
        "        tree.fit(X_mini_train, y_mini_train)\n",
        "\n",
        "        y_pred = tree.predict(data_split[1])\n",
        "        accuracy_scores.append(accuracy_score(data_split[3], y_pred))\n",
        "\n",
        "    avg_acc = np.mean(accuracy_scores)\n",
        "\n",
        "    return forest, avg_acc\n",
        "\n",
        "def majority_vote_pred(forest, num_trees, data_split):\n",
        "\n",
        "    Y_pred = np.empty([num_trees, len(data_split[1])], dtype=np.uint8)\n",
        "\n",
        "    for tree_index, tree in enumerate(forest):\n",
        "        Y_pred[tree_index] = tree.predict(data_split[1])\n",
        "\n",
        "    y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)\n",
        "    score = accuracy_score(data_split[3], y_pred_majority_votes.reshape([-1]))\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNP0G18gSKzv",
        "outputId": "69037dec-dca0-411c-db6b-41d80d9c609b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy (100): 0.7661950000000001\n",
            "\n",
            "Majority vote accuracy (100): 0.805\n",
            "\n",
            "Average accuracy (1000): 0.821665\n",
            "\n",
            "Majority vote accuracy (1000): 0.8245\n",
            "\n",
            "Average accuracy (10000): 0.81727035\n",
            "\n",
            "Majority vote accuracy (10000): 0.82015\n",
            "\n",
            "Average accuracy (100000): 0.818873075\n",
            "\n",
            "Majority vote accuracy (100000): 0.819\n",
            "\n"
          ]
        }
      ],
      "source": [
        "k = 10\n",
        "for dataset, tree_model in zip(data_splits, tree_models):\n",
        "    size = 10 * k\n",
        "    n_trees = 1000\n",
        "\n",
        "    mini_sets = build_mini_sets(size, dataset, n_trees)\n",
        "\n",
        "    forest, avg_acc = build_forest(tree_model, n_trees, mini_sets, dataset)\n",
        "    print(f\"Average accuracy ({size}): {avg_acc}\\n\")\n",
        "\n",
        "    majority_vote = majority_vote_pred(forest, n_trees, dataset)\n",
        "    print(f\"Majority vote accuracy ({size}): {majority_vote}\\n\")\n",
        "\n",
        "    k = k*10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL77czDmWy-u"
      },
      "source": [
        "We can see minor improvements from majority vote, compared to a simple average prediction, on accuracy. Still, the interesting phenomena of decreased performance on bigger datasets hold. Nevertheless, the difference throughout different dataset sizes is smaller (changes observed at the three decimal place) so majority voting provides slightly better but more consistent scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaLvR_zdSr62"
      },
      "source": [
        "### Part II\n",
        "\n",
        "New dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwMZ7F20aYAu",
        "outputId": "ae902868-27cf-4e7a-9b29-11d223d3ed06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ],
      "source": [
        "%pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtaeSgpVaYHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c595a34-1ed3-41aa-e42c-426642fc17bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xDZWvIZaYOF"
      },
      "outputs": [],
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kZSzrCMaYVz"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX3HjiFIa6I6",
        "outputId": "b3b90cbd-9458-4206-c996-08e73d7653ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading steel-dataset.zip to /content\n",
            "\r  0% 0.00/484k [00:00<?, ?B/s]\n",
            "\r100% 484k/484k [00:00<00:00, 111MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download nimapourmoradi/steel-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQCv1G-fWy-y"
      },
      "source": [
        "## Steel dataset\n",
        "\n",
        "The information gathered is from the DAEWOO Steel Co. Ltd in Gwangyang, South Korea. It produces several types of coils, steel plates, and iron plates. The information on electricity consumption is held in a cloud-based system. The information on energy consumption of the industry is stored on the website of the Korea Electric Power Corporation (pccs.kepco.go.kr), and the perspectives on daily, monthly, and annual data are calculated and shown.\n",
        "\n",
        "The goal is to classify load type on one of the following class labels: Light Load, Medium Load, Maximum Load.\n",
        "\n",
        "This is an interesting dataset because it contains variables of varying type (float, integer, and strings), thus it requires preprocessing for standardizing numerical features (Usage_kWh, Lagging_Current_Reactive.Power_kVarh, Leading_Current_Reactive_Power_kVarh, CO2 (tCO2), Lagging_Current_Power_Factor, Leading_Current_Power_Factor, NSM) and encoding text labels (WeekStatus, Day_Of_Week).\n",
        "\n",
        "It has 35041 observations and no missing values. To follow the book's exercise, I will split the dataset into a similar ratio of 25:5:5 for building the training, validation, and testing sets.\n",
        "\n",
        "----\n",
        "\n",
        "The data can be obtained from Kaggle -> https://www.kaggle.com/datasets/nimapourmoradi/steel-dataset\n",
        "\n",
        "Efficient energy consumption prediction model for a data analytic-enabled industry building in a smart city By Sathishkumar V E, Changsun Shin, Yongyun Cho. 2021\n",
        "\n",
        "Published in Building Research & Information, Vol. 49. no. 1, pp. 127-143"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTc7JuJVbR1J"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip_and_extract(file_path):\n",
        "  \"\"\"\n",
        "  Unzips a folder and extracts the information.\n",
        "\n",
        "  Args:\n",
        "      file_path: The path to the zip file.\n",
        "  \"\"\"\n",
        "\n",
        "  # Open the zip file\n",
        "  with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    # Extract all files\n",
        "    zip_ref.extractall()\n",
        "\n",
        "unzip_and_extract(\"/content/steel-dataset.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "7orjvDfTStiQ",
        "outputId": "1dea19d0-6c33-4b8d-d249-b730763dc6a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date_Time  Usage_kWh  Lagging_Current_Reactive.Power_kVarh  \\\n",
              "0  01/01/2018 00:15       3.17                                  2.95   \n",
              "1  01/01/2018 00:30       4.00                                  4.46   \n",
              "2  01/01/2018 00:45       3.24                                  3.28   \n",
              "3  01/01/2018 01:00       3.31                                  3.56   \n",
              "4  01/01/2018 01:15       3.82                                  4.50   \n",
              "\n",
              "   Leading_Current_Reactive_Power_kVarh  CO2(tCO2)  \\\n",
              "0                                   0.0        0.0   \n",
              "1                                   0.0        0.0   \n",
              "2                                   0.0        0.0   \n",
              "3                                   0.0        0.0   \n",
              "4                                   0.0        0.0   \n",
              "\n",
              "   Lagging_Current_Power_Factor  Leading_Current_Power_Factor   NSM  \\\n",
              "0                         73.21                         100.0   900   \n",
              "1                         66.77                         100.0  1800   \n",
              "2                         70.28                         100.0  2700   \n",
              "3                         68.09                         100.0  3600   \n",
              "4                         64.72                         100.0  4500   \n",
              "\n",
              "  WeekStatus Day_Of_Week   Load_Type  \n",
              "0    Weekday      Monday  Light_Load  \n",
              "1    Weekday      Monday  Light_Load  \n",
              "2    Weekday      Monday  Light_Load  \n",
              "3    Weekday      Monday  Light_Load  \n",
              "4    Weekday      Monday  Light_Load  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88d42c0b-5322-442b-b0b8-601cf74be2d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date_Time</th>\n",
              "      <th>Usage_kWh</th>\n",
              "      <th>Lagging_Current_Reactive.Power_kVarh</th>\n",
              "      <th>Leading_Current_Reactive_Power_kVarh</th>\n",
              "      <th>CO2(tCO2)</th>\n",
              "      <th>Lagging_Current_Power_Factor</th>\n",
              "      <th>Leading_Current_Power_Factor</th>\n",
              "      <th>NSM</th>\n",
              "      <th>WeekStatus</th>\n",
              "      <th>Day_Of_Week</th>\n",
              "      <th>Load_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01/01/2018 00:15</td>\n",
              "      <td>3.17</td>\n",
              "      <td>2.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.21</td>\n",
              "      <td>100.0</td>\n",
              "      <td>900</td>\n",
              "      <td>Weekday</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Light_Load</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01/01/2018 00:30</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.77</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1800</td>\n",
              "      <td>Weekday</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Light_Load</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01/01/2018 00:45</td>\n",
              "      <td>3.24</td>\n",
              "      <td>3.28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70.28</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2700</td>\n",
              "      <td>Weekday</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Light_Load</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01/01/2018 01:00</td>\n",
              "      <td>3.31</td>\n",
              "      <td>3.56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.09</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3600</td>\n",
              "      <td>Weekday</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Light_Load</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01/01/2018 01:15</td>\n",
              "      <td>3.82</td>\n",
              "      <td>4.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.72</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4500</td>\n",
              "      <td>Weekday</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Light_Load</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88d42c0b-5322-442b-b0b8-601cf74be2d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88d42c0b-5322-442b-b0b8-601cf74be2d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88d42c0b-5322-442b-b0b8-601cf74be2d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a36ad157-f410-4e80-b811-5b36d417a982\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a36ad157-f410-4e80-b811-5b36d417a982')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a36ad157-f410-4e80-b811-5b36d417a982 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 35041,\n  \"fields\": [\n    {\n      \"column\": \"Date_Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 35040,\n        \"samples\": [\n          \"29/04/2018 07:15\",\n          \"04/10/2018 12:00\",\n          \"26/01/2018 11:30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Usage_kWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.44413284594445,\n        \"min\": 0.0,\n        \"max\": 157.18,\n        \"num_unique_values\": 3344,\n        \"samples\": [\n          81.0,\n          59.47,\n          9.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lagging_Current_Reactive.Power_kVarh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.305915990014512,\n        \"min\": 0.0,\n        \"max\": 96.91,\n        \"num_unique_values\": 1954,\n        \"samples\": [\n          20.88,\n          69.84,\n          7.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leading_Current_Reactive_Power_kVarh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.424862991024686,\n        \"min\": 0.0,\n        \"max\": 27.76,\n        \"num_unique_values\": 769,\n        \"samples\": [\n          11.59,\n          23.04,\n          9.97\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CO2(tCO2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016150708405657126,\n        \"min\": 0.0,\n        \"max\": 0.07,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.02,\n          0.04,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lagging_Current_Power_Factor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.921336735842242,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 5079,\n        \"samples\": [\n          77.48,\n          46.28,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leading_Current_Power_Factor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.458030196745824,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 3366,\n        \"samples\": [\n          97.26,\n          54.38,\n          19.51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NSM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24940,\n        \"min\": 0,\n        \"max\": 85500,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          72900,\n          70200,\n          66600\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WeekStatus\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Weekend\",\n          \"Weekday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Day_Of_Week\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Monday\",\n          \"Tuesday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Load_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Light_Load\",\n          \"Medium_Load\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# 8 Voting Classifier on Steel Dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/Steel_industry.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktHAZd5RlxVH",
        "outputId": "c24b0d7d-b665-4081-c286-6e7b4c0e829f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WeekStatus     2\n",
              "Day_Of_Week    7\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data[['WeekStatus', 'Day_Of_Week']].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIcaQ5CtbzHY",
        "outputId": "aa5be3f9-5397-4471-ff9f-61bd8f859e6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Date_Time                                object\n",
              " Usage_kWh                               float64\n",
              " Lagging_Current_Reactive.Power_kVarh    float64\n",
              " Leading_Current_Reactive_Power_kVarh    float64\n",
              " CO2(tCO2)                               float64\n",
              " Lagging_Current_Power_Factor            float64\n",
              " Leading_Current_Power_Factor            float64\n",
              " NSM                                       int64\n",
              " WeekStatus                               object\n",
              " Day_Of_Week                              object\n",
              " Load_Type                                object\n",
              " dtype: object,\n",
              " (35041, 9),\n",
              " (35041, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X, y = data.iloc[:, 1:10].to_numpy(), data.iloc[:, 10:].to_numpy()\n",
        "\n",
        "data.dtypes, X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1w4JIFyTsFL"
      },
      "outputs": [],
      "source": [
        "# Split into train, val, test\n",
        "## 50:10:10 ratio for MNIST; 25:5:5 ratio for Steel\n",
        "X_train, y_train = X[:25_000], y[:25_000]\n",
        "X_val, y_val = X[25_000:30_000], y[25_000:30_000]\n",
        "X_test, y_test = X[30_000:], y[30_000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIvr-U5zfa2f",
        "outputId": "19de26c7-2f3f-46e3-ee5c-178916317c88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.17, 2.95, 0.0, 0.0, 73.21, 100.0, 900, 'Weekday', 'Monday'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "X_train[0] # one unprocessed training observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJnBGzcDWy-1"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "#### Numeric Features Preprocessing\n",
        "\n",
        "The numeric_features_idx indicates the indexes of numeric columns in the dataset, which are subjected to two main preprocessing steps within a Pipeline:\n",
        "\n",
        "**Imputation**: Uses SimpleImputer with a strategy of 'median' to fill in any missing values with the median of the column. Even though it's mentioned that the dataset has no missing values, this step could be a precautionary measure to handle potential anomalies or future data that might have missing entries.\n",
        "\n",
        "**Scaling**: Applies StandardScaler to normalize the numeric features. This scaler removes the mean and scales the features to unit variance. This step is crucial for models that are sensitive to the magnitude of variables, ensuring that all numeric features contribute equally to the model's performance.\n",
        "\n",
        "#### Categorical Features Preprocessing\n",
        "\n",
        "The *categorical_features_idx* lists the indexes of categorical columns, which go through their preprocessing pipeline:\n",
        "\n",
        "**Imputation**: Similarly, ***SimpleImputer*** is used but with a strategy of 'constant' and a fill_value of 'missing'. This approach handles any potential missing values by assigning them a constant label ('missing'), ensuring that the encoder can process these values later.\n",
        "\n",
        "**One-Hot Encoding**: Utilizes ***OneHotEncoder*** to convert categorical variables into a format that can be provided to ML algorithms. Since machine learning models require numerical input, this step transforms categorical variables into a binary matrix representing the presence (or absence) of a category. This is particularly important for models that cannot handle categorical values directly.\n",
        "\n",
        "#### Column Transformation\n",
        "\n",
        "***ColumnTransformer*** is then used to apply these preprocessing steps to their respective columns in the dataset. This transformer allows for different columns or column subsets of the input to be transformed separately and the results concatenated into a single feature space. This is especially useful in datasets like this one, where we have a mix of numerical and categorical inputs.\n",
        "\n",
        "\n",
        "The transformed features are applied to the training, validation, and testing sets. Notably, the validation and testing sets use the .transform() method instead of .fit_transform() for the testing set to ensure that they are scaled or encoded based on the parameters learned from the training set, preventing data leakage.\n",
        "\n",
        "#### Label Encoding\n",
        "\n",
        "Finally, the target labels (y_train, y_val, y_test) are encoded using ***LabelEncoder***. This encoder converts the class labels into integers, which is necessary for most machine learning models in sklearn that require numerical labels. It's important to note that the encoder is fitted only on the training data to establish a consistent mapping of classes to integers, then applied to both training and testing labels to ensure consistency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P337IgQfj2T",
        "outputId": "8a51ee3c-217c-4ce5-cfab-397a4bf4d26f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
          ]
        }
      ],
      "source": [
        "# data processing\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "numeric_features_idx = list(range(0, 7))\n",
        "categorical_features_idx = list(range(7, 9))\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "# Define the preprocessing for categorical features (encode them)\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder())])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features_idx),\n",
        "        ('cat', categorical_transformer, categorical_features_idx)])\n",
        "\n",
        "\n",
        "X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "X_val_transformed = preprocessor.fit_transform(X_val)\n",
        "X_test_transformed = preprocessor.transform(X_test)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on the training data and transform both training and test labels\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.fit_transform(y_val)\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4dQWaS6kwO1",
        "outputId": "2dbb938f-4a06-42eb-e96a-b89845da3e2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.73996798, -0.62276433, -0.51506717, -0.73103916, -0.39928842,\n",
              "         0.50404433, -1.67629364,  1.        ,  0.        ,  0.        ,\n",
              "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ]),\n",
              " 0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X_train_transformed[0], y_train_encoded[0] # 7 numerical + 9 one hot encoded (7 days and 2 week status)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1pZ76YrWy-3"
      },
      "source": [
        "I consider three models to build the ensemble: Logistic Regression, Support Vector Classifier, and a Decision Tree Classifier.\n",
        "\n",
        "The choice was motivated by the multinomial classification task, we have multiple class labels any given observation can be classified into, and because of their mainstream usage in the literature for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckQHjozeVd07",
        "outputId": "c2f414fb-d2f7-4457-bc89-88d9d1216af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the LR\n",
            "Training the SVC\n",
            "Training the DTC\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('LR',\n",
        "                  LogisticRegression(solver ='lbfgs',\n",
        "                                     multi_class ='multinomial',\n",
        "                                     max_iter = 200)))\n",
        "estimators.append(('SVC', SVC(gamma ='auto',\n",
        "                              probability = True)))\n",
        "estimators.append(('DTC', DecisionTreeClassifier()))\n",
        "\n",
        "for estimator, fitm in estimators:\n",
        "    print(\"Training the\", estimator)\n",
        "    fitm.fit(X_train_transformed, y_train_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3vo5u9Jnv3L",
        "outputId": "e7ca64af-6dfd-48d6-9c4a-f044d547b60f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7768, 0.8312, 0.851]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# note the logistic regression performs significantly worse than SVC and DTC.\n",
        "# thus I will only consider the latter two for building my ensemble\n",
        "\n",
        "[fitm.score(X_val_transformed, y_val_encoded) for estimator, fitm in estimators]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "ngYOKPySV6ug",
        "outputId": "d11f615d-61c2-47c3-d6db-e3aef00afb9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('SVC', SVC(gamma='auto', probability=True)),\n",
              "                             ('DTC', DecisionTreeClassifier())],\n",
              "                 voting='soft')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;SVC&#x27;, SVC(gamma=&#x27;auto&#x27;, probability=True)),\n",
              "                             (&#x27;DTC&#x27;, DecisionTreeClassifier())],\n",
              "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;SVC&#x27;, SVC(gamma=&#x27;auto&#x27;, probability=True)),\n",
              "                             (&#x27;DTC&#x27;, DecisionTreeClassifier())],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>SVC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;, probability=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>DTC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Voting Classifier with soft voting\n",
        "vot_hard = VotingClassifier(estimators = estimators[1:], voting ='hard')\n",
        "vot_hard.fit(X_train_transformed, y_train_encoded)\n",
        "\n",
        "# Voting Classifier with soft voting\n",
        "vot_soft = VotingClassifier(estimators = estimators[1:], voting ='soft')\n",
        "vot_soft.fit(X_train_transformed, y_train_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8AXEuq_o1LD",
        "outputId": "f4dbd277-0b8b-415b-8459-b3624f5ab96b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8354"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "vot_hard.score(X_val_transformed, y_val_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzkrUPSCY-ms",
        "outputId": "94cd48e1-aa9d-4442-e15f-7efa4dee27a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8494"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "vot_soft.score(X_val_transformed, y_val_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3s_eZUZWy-7"
      },
      "source": [
        "Voting classifiers are a type of ensemble learning technique where multiple models, often of different types, are trained on the same data and then used to predict the output class. The final output class is determined based on the votes from all the models. The main idea is to combine the decision-making capabilities of various models to reduce overfitting, increase robustness, and improve the overall prediction accuracy.\n",
        "\n",
        "There are two main types of voting:\n",
        "\n",
        "**Hard Voting**: In hard voting, each model in the ensemble votes for a single class, and the class with the majority of the votes is chosen as the final prediction. This method does not take into account the confidence of the votes; it only counts the number of votes.\n",
        "\n",
        "**Soft Voting**: Soft voting, on the other hand, takes into account the probability estimates (confidence) of the vote. Each model's vote is weighted by its confidence in the prediction. The final output class is the one with the highest sum of predicted probabilities. This method is often more flexible and achieves higher performance because it leverages the predictive confidence of each model.\n",
        "\n",
        "#### Code Explanation\n",
        "\n",
        "The code initializes three different classifiers: Logistic Regression, Support Vector Classifier (SVC), and Decision Tree Classifier (DTC), each with specific hyperparameters suited to the dataset and the task at hand. These classifiers are added to a list called estimators.\n",
        "\n",
        "- **Logistic Regression (LR)**: Configured for multinomial classification, suitable for multiclass problems.\n",
        "- **Support Vector Classifier (SVC)**: Enabled with probability=True to allow the use of soft voting, as it requires probability estimates for each class.\n",
        "- **Decision Tree Classifier (DTC)**: A straightforward implementation without specified hyperparameters, demonstrating its versatility.\n",
        "\n",
        "Each classifier is then trained (fit) on the transformed training dataset (X_train_transformed) and the encoded target labels (y_train_encoded).\n",
        "\n",
        "##### Ensemble Models with Voting Classifier\n",
        "\n",
        "Two instances of the ***VotingClassifier*** are created, differing in their voting strategies: one uses hard voting (vot_hard), and the other employs soft voting (vot_soft). Both are configured with a subset of the previously defined classifiers.\n",
        "\n",
        "After instantiation, both voting classifiers are trained on the same dataset. This training process leverages the strengths of the included classifiers to make more accurate predictions based on the collective decision-making process defined by the voting strategy.\n",
        "\n",
        "The performance of the hard voting classifier is evaluated on a validation set (X_val_transformed, y_val_encoded), demonstrating its ability to generalize the learned patterns to new data. It achieves a score of 0.8346. Similarly, the soft voting classifier is evaluated, achieving a higher score of 0.8586, indicating that, in this case, leveraging the confidence levels of the predictions (soft voting) provides a more accurate model than merely counting votes (hard voting)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgPWUqSpp2dL",
        "outputId": "d9dcea00-05cd-45e1-b98c-366eeb507de8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# 9 Stacking Ensemble on Steel Dataset\n",
        "\n",
        "X_valid_predictions = np.empty((len(X_val_transformed), len(estimators)), dtype=object)\n",
        "idx = 0\n",
        "for estimator, fitm in estimators:\n",
        "    print(idx)\n",
        "    X_valid_predictions[:, idx] = fitm.predict(X_val_transformed)\n",
        "    idx += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vN9qD9TUlAJ",
        "outputId": "bee45a67-f1fb-4c85-e30e-92086bf99a3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1],\n",
              "       [1, 1, 1],\n",
              "       [1, 1, 1],\n",
              "       ...,\n",
              "       [1, 1, 1],\n",
              "       [1, 1, 1],\n",
              "       [1, 1, 1]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "X_valid_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "GaAbZjTsU8BQ",
        "outputId": "aa37d083-85ea-4469-bf27-f73bedbcaaff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "rnd_forest_blender = RandomForestClassifier(n_estimators=200, oob_score=True,\n",
        "                                            random_state=42)\n",
        "rnd_forest_blender.fit(X_valid_predictions, y_val_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyDDXx11VAGH",
        "outputId": "e4d64a8a-b390-446a-cfc6-8c519a61754a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.872"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "rnd_forest_blender.oob_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0LhuSVdWBQr"
      },
      "outputs": [],
      "source": [
        "X_test_predictions = np.empty((len(X_test_transformed), len(estimators)), dtype=object)\n",
        "idx = 0\n",
        "for estimator, fitm in estimators:\n",
        "    X_test_predictions[:, idx] = fitm.predict(X_test_transformed)\n",
        "    idx += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXWF1b1YXu_b",
        "outputId": "fba9c437-941b-4877-c1ec-5f234039fe45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7266415393771077"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "y_pred = rnd_forest_blender.predict(X_test_predictions)\n",
        "accuracy_score(y_test_encoded, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "r2xdVrkiXvEY",
        "outputId": "f18be52a-db0c-4bb4-bae0-94ac0214dec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingClassifier(estimators=[('LR',\n",
              "                                LogisticRegression(max_iter=200,\n",
              "                                                   multi_class='multinomial')),\n",
              "                               ('SVC', SVC(gamma='auto', probability=True)),\n",
              "                               ('DTC', DecisionTreeClassifier())],\n",
              "                   final_estimator=RandomForestClassifier(n_estimators=200,\n",
              "                                                          oob_score=True,\n",
              "                                                          random_state=42))"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;LR&#x27;,\n",
              "                                LogisticRegression(max_iter=200,\n",
              "                                                   multi_class=&#x27;multinomial&#x27;)),\n",
              "                               (&#x27;SVC&#x27;, SVC(gamma=&#x27;auto&#x27;, probability=True)),\n",
              "                               (&#x27;DTC&#x27;, DecisionTreeClassifier())],\n",
              "                   final_estimator=RandomForestClassifier(n_estimators=200,\n",
              "                                                          oob_score=True,\n",
              "                                                          random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;LR&#x27;,\n",
              "                                LogisticRegression(max_iter=200,\n",
              "                                                   multi_class=&#x27;multinomial&#x27;)),\n",
              "                               (&#x27;SVC&#x27;, SVC(gamma=&#x27;auto&#x27;, probability=True)),\n",
              "                               (&#x27;DTC&#x27;, DecisionTreeClassifier())],\n",
              "                   final_estimator=RandomForestClassifier(n_estimators=200,\n",
              "                                                          oob_score=True,\n",
              "                                                          random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LR</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>SVC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;, probability=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>DTC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "## with stacking classifier\n",
        "### Since StackingClassifier uses K-Fold cross-validation, we don't need a separate validation set,\n",
        "###so let's join the training set and the validation set into a bigger training set:\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "X_train_full, y_train_full = X[:30_000], y[:30_000]\n",
        "X_train_full_transformed = preprocessor.fit_transform(X_train_full)\n",
        "y_train_full_encoded = label_encoder.fit_transform(y_train_full)\n",
        "\n",
        "stack_clf = StackingClassifier(estimators,\n",
        "                               final_estimator=rnd_forest_blender)\n",
        "stack_clf.fit(X_train_full_transformed, y_train_full_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6ek5niBWPS_",
        "outputId": "87f2a021-d6a1-4098-96eb-2c6ddc0667ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6881571116841897"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "stack_clf.score(X_test_transformed, y_test_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3FnVM8lWy_E"
      },
      "source": [
        "#### Random Forest\n",
        "\n",
        "A Random Forest is an ensemble learning method that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random forests correct for decision trees' habit of overfitting to their training set. They are highly versatile, can handle both classification and regression tasks, and can manage datasets with a mix of numerical and categorical features. The oob_score (Out-of-Bag score) is a measure of prediction accuracy that can be used as an alternative to cross-validation. It is calculated using predictions from the trees that did not use a given data point during training, providing an efficient estimate of the model's performance.\n",
        "\n",
        "#### Stacking\n",
        "\n",
        "Stacking involves training a new model to aggregate the predictions of several base models. The base models are trained on the full training set, then a new model (called the blender or meta-learner) is trained on the outputs of these base models as features. This approach can lead to better predictive performance compared to using any single model alone because it combines the strengths of various models. The key idea is that the blender learns how to best combine the predictions from the base models.\n",
        "\n",
        "#### Comparison of Ensemble Models\n",
        "\n",
        "In the literature, both random forests and stacking are well-regarded for their ability to improve prediction accuracy through ensemble methods. Studies and empirical evidence suggest that ensemble methods can outperform individual estimators by reducing variance (bagging, random forests), reducing bias (boosting), or increasing the predictive force through diversity (stacking). Each method has its context where it shines, with stacking often being highlighted for its ability to blend the predictive power of highly varied models through a meta-learner.\n",
        "\n",
        "In the provided code, stacking is implemented manually using predictions from multiple estimators as input features for a random forest blender. The estimators (Logistic Regression, SVC, and Decision Tree Classifier) predict the validation set, and these predictions are used as features for the random forest model to fit. This process is called blending when using a hold-out set (like a validation set) to train the blender.\n",
        "\n",
        "I found it quite interesting that the accuracy score dropped significantly in the stacking model. Some potential causes of this discrepancy include:\n",
        "\n",
        "- **Overfitting in Blender Model**: The Random Forest blender might be overfitting the validation predictions (X_valid_predictions). An OOB score of 0.8718 suggests the blender performs well on the training data, but this might not generalize well to unseen data, as observed with the test set accuracy (0.7445).\n",
        "\n",
        "- **Mismatch in Data Distribution**: The stacking classifier's performance might suffer due to differences in the distribution of the training set (including the validation set now) and the test set. Joining the training and validation sets into a bigger training set changes the data's distribution, which the final estimator is trained on.\n",
        "\n",
        "- **Complexity and Diversity of Base Estimators**: The effectiveness of stacking and blending techniques heavily depends on the diversity and accuracy of the base estimators. If the base estimators are too correlated or if there's not enough diversity in their predictions, the final model may not significantly improve or could even perform worse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKbmMyCnZBXf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}